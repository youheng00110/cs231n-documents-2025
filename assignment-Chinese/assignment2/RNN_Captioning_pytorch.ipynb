{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ReJjSfEiM4Os"
   },
   "outputs": [],
   "source": [
    "# 这会将你的Google Drive挂载到Colab虚拟机上\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 待办：输入你在Drive中保存解压后的作业文件夹的路径，\n",
    "# 例如 'cs231n/assignments/assignment2/'\n",
    "FOLDERNAME = \"cs231n/assignments/assignment2/\"\n",
    "assert FOLDERNAME is not None, \"[!] 请输入文件夹名称。\"\n",
    "\n",
    "# 现在我们已经挂载了你的Drive，这将确保\n",
    "# Colab虚拟机的Python解释器能够从其中加载\n",
    "# Python文件\n",
    "import sys\n",
    "sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n",
    "\n",
    "# 这会将COCO数据集下载到你的Drive中\n",
    "# 如果它还不存在的话\n",
    "%cd /content/drive/My\\ Drive/$FOLDERNAME/cs231n/datasets/\n",
    "!bash get_coco_dataset.sh  # 执行bash脚本下载COCO数据集\n",
    "%cd /content/drive/My\\ Drive/$FOLDERNAME  # 切换回作业主目录"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w_iEsIkpM4Ot",
    "tags": [
     "pdf-title"
    ]
   },
   "source": [
    "# 使用循环神经网络（RNN）进行图像 caption 生成\n",
    "在本练习中，你将实现基础的循环神经网络（vanilla Recurrent Neural Networks），并使用它们训练一个能够为图像生成新 caption 的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gE6g5u9RM4Ou",
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [],
   "source": [
    "# 设置单元格\n",
    "import time, os, json  # 导入时间、操作系统、JSON处理相关模块\n",
    "import numpy as np  # 导入NumPy库，用于数值计算\n",
    "import torch  # 导入PyTorch库\n",
    "import matplotlib.pyplot as plt  # 导入Matplotlib库，用于绘图\n",
    "\n",
    "# 从cs231n包中导入相关模块和函数\n",
    "from cs231n.gradient_check import eval_numerical_gradient, eval_numerical_gradient_array  # 梯度检查函数\n",
    "from cs231n.rnn_layers_pytorch import *  # PyTorch的RNN层相关实现\n",
    "from cs231n.captioning_solver_pytorch import CaptioningSolverPytorch  # 图像caption生成的求解器\n",
    "from cs231n.classifiers.rnn_pytorch import CaptioningRNN  # 用于caption生成的RNN分类器\n",
    "from cs231n.coco_utils import load_coco_data, sample_coco_minibatch, decode_captions  # COCO数据集处理工具\n",
    "from cs231n.image_utils import image_from_url  # 从URL获取图像的工具\n",
    "\n",
    "# 设置Matplotlib在 notebook 中内嵌显示\n",
    "%matplotlib inline  \n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0)  # 设置图表默认大小\n",
    "plt.rcParams['image.interpolation'] = 'nearest'  # 设置图像插值方式为最近邻\n",
    "plt.rcParams['image.cmap'] = 'gray'  # 设置默认图像颜色映射为灰度\n",
    "\n",
    "%load_ext autoreload  # 加载自动重载扩展\n",
    "%autoreload 2  # 设置自动重载模式，修改模块后自动重新导入\n",
    "\n",
    "\n",
    "def rel_error(x, y):\n",
    "    \"\"\" 返回相对误差 \"\"\"\n",
    "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5mAU30MMM4Ou",
    "tags": [
     "pdf-ignore"
    ]
   },
   "source": [
    "# COCO 数据集\n",
    "在本练习中，我们将使用 [COCO 数据集](https://cocodataset.org/)的 2014 年版本，这是一个图像 caption 生成任务的标准测试集。该数据集包含 80,000 张训练图像和 40,000 张验证图像，每张图像都配有 5 条由 Amazon Mechanical Turk 平台工作者编写的 caption。\n",
    "\n",
    "**图像特征**：我们已经对数据进行了预处理并提取了特征。对于所有图像，我们从在 ImageNet 上预训练的 VGG-16 网络的 fc7 层提取了特征，这些特征存储在文件 `train2014_vgg16_fc7.h5` 和 `val2014_vgg16_fc7.h5` 中。为了减少处理时间和内存需求，我们使用主成分分析（PCA）将特征维度从 4096 降至 512，这些降维后的特征存储在文件 `train2014_vgg16_fc7_pca.h5` 和 `val2014_vgg16_fc7_pca.h5` 中。原始图像占用近 20GB 空间，因此我们未包含在下载内容中。由于所有图像均来自 Flickr，我们将训练和验证图像的 URL 存储在文件 `train2014_urls.txt` 和 `val2014_urls.txt` 中，这样你可以实时下载图像用于可视化。\n",
    "\n",
    "**Captions（图像描述）**：直接处理字符串效率较低，因此我们将使用编码后的 caption。每个单词都被分配一个整数 ID，这样我们就可以用整数序列表示一条 caption。整数 ID 与单词之间的映射关系在文件 `coco2014_vocab.json` 中，你可以使用 `cs231n/coco_utils.py` 文件中的 `decode_captions` 函数将整数 ID 的 NumPy 数组转换回字符串。\n",
    "\n",
    "**特殊标记（Tokens）**：我们在词汇表中添加了几个特殊标记，并且已经处理了所有与特殊标记相关的实现细节。我们在每条 caption 的开头添加一个特殊的 `<START>` 标记，在结尾添加一个 `<END>` 标记。罕见词会被替换为特殊的 `<UNK>` 标记（表示“未知”）。此外，由于我们希望在包含不同长度 caption 的小批量数据上进行训练，因此会在短 caption 的 `<END>` 标记后填充特殊的 `<NULL>` 标记，并且不会对 `<NULL>` 标记计算损失或梯度。\n",
    "\n",
    "你可以使用 `cs231n/coco_utils.py` 文件中的 `load_coco_data` 函数加载所有 COCO 数据（包括 caption、特征、URL 和词汇表）。运行下面的单元格进行加载："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pn8-6ZslM4Ov",
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [],
   "source": [
    "# 将COCO数据从磁盘加载到一个字典中\n",
    "# 在本作业的剩余部分，我们将使用降维后的特征\n",
    "# 但你也可以通过修改下面的标志自行尝试原始特征\n",
    "data = load_coco_data(pca_features=True)  # 加载COCO数据，使用PCA降维后的特征\n",
    "\n",
    "# 打印数据字典中的所有键和对应的值信息\n",
    "for k, v in data.items():\n",
    "    if type(v) == np.ndarray:  # 如果值是NumPy数组\n",
    "        print(k, type(v), v.shape, v.dtype)  # 打印键、类型、形状、数据类型\n",
    "    else:\n",
    "        print(k, type(v), len(v))  # 打印键、类型、长度（非数组类型）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kSoNi-GDM4Ov"
   },
   "source": [
    "## 查看数据\n",
    "在处理数据集之前，查看数据集中的示例总是一个好主意。\n",
    "\n",
    "你可以使用`cs231n/coco_utils.py`文件中的`sample_coco_minibatch`函数，从`load_coco_data`返回的数据结构中抽取小批量数据样本。运行下面的代码，抽取一小批量训练数据，并显示图像及其对应的描述。多次运行并查看结果，有助于你了解这个数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h8SkYMVjM4Ov"
   },
   "outputs": [],
   "source": [
    "# 抽取一个小批量数据并显示图像及其描述\n",
    "# 如果出现错误，可能是URL已失效，不用担心！\n",
    "# 你可以任意多次重新抽取\n",
    "batch_size = 3  # 小批量数据的大小\n",
    "\n",
    "# 从数据中抽取小批量数据，返回caption、特征和图像URL\n",
    "captions, features, urls = sample_coco_minibatch(data, batch_size=batch_size)\n",
    "\n",
    "# 遍历每个样本，显示图像和对应的描述\n",
    "for i, (caption, url) in enumerate(zip(captions, urls)):\n",
    "    plt.imshow(image_from_url(url))  # 从URL加载并显示图像\n",
    "    plt.axis('off')  # 关闭坐标轴显示\n",
    "    caption_str = decode_captions(caption, data['idx_to_word'])  # 将整数ID序列解码为字符串描述\n",
    "    plt.title(caption_str)  # 设置图像标题为解码后的描述\n",
    "    plt.show()  # 显示图像"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cfh1t1ROM4Ow"
   },
   "source": [
    "# 循环神经网络（RNN）\n",
    "正如课堂上所讨论的，我们将使用循环神经网络（RNN）语言模型来进行图像 caption 生成。`cs231n/rnn_layers_pytorch.py` 文件包含了循环神经网络所需的不同层类型的实现，而 `cs231n/classifiers/rnn_pytorch.py` 文件则利用这些层来实现图像 caption 生成模型。\n",
    "\n",
    "我们首先要在 `cs231n/rnn_layers_pytorch.py` 中实现不同类型的 RNN 层。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SiqMvjIM4Ow"
   },
   "source": [
    "# 基础 RNN：单步前向传播\n",
    "打开文件 `cs231n/rnn_layers_pytorch.py`。该文件实现了循环神经网络中常用的不同类型层的前向传播。注意，由于我们使用 PyTorch，反向传播将由 PyTorch 的自动求导（autograd）机制处理。\n",
    "\n",
    "首先实现函数 `rnn_step_forward`，该函数用于实现基础循环神经网络单个时间步的前向传播。完成后，运行下面的代码检查你的实现。你应该会看到误差在 e-8 量级或更小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Z8cvCN7M4Ow"
   },
   "outputs": [],
   "source": [
    "N, D, H = 3, 10, 4  # N：批量大小，D：输入特征维度，H：隐藏层维度\n",
    "\n",
    "# 创建输入数据x（形状为N×D），从-0.4到0.7均匀生成N*D个值\n",
    "x = torch.from_numpy(np.linspace(-0.4, 0.7, num=N*D).reshape(N, D))\n",
    "# 创建前一时间步的隐藏状态prev_h（形状为N×H），从-0.2到0.5均匀生成N*H个值\n",
    "prev_h = torch.from_numpy(np.linspace(-0.2, 0.5, num=N*H).reshape(N, H))\n",
    "# 创建输入到隐藏层的权重矩阵Wx（形状为D×H），从-0.1到0.9均匀生成D*H个值\n",
    "Wx = torch.from_numpy(np.linspace(-0.1, 0.9, num=D*H).reshape(D, H))\n",
    "# 创建隐藏层到隐藏层的权重矩阵Wh（形状为H×H），从-0.3到0.7均匀生成H*H个值\n",
    "Wh = torch.from_numpy(np.linspace(-0.3, 0.7, num=H*H).reshape(H, H))\n",
    "# 创建偏置项b（长度为H），从-0.2到0.4均匀生成H个值\n",
    "b = torch.from_numpy(np.linspace(-0.2, 0.4, num=H))\n",
    "\n",
    "# 执行RNN单步前向传播，将结果转换为numpy数组\n",
    "next_h = rnn_step_forward(x, prev_h, Wx, Wh, b).numpy()\n",
    "# 预期的输出结果（用于验证实现正确性）\n",
    "expected_next_h = np.asarray([\n",
    "  [-0.58172089, -0.50182032, -0.41232771, -0.31410098],\n",
    "  [ 0.66854692,  0.79562378,  0.87755553,  0.92795967],\n",
    "  [ 0.97934501,  0.99144213,  0.99646691,  0.99854353]])\n",
    "\n",
    "# 计算并打印next_h与预期结果的相对误差\n",
    "print('next_h error: ', rel_error(expected_next_h, next_h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8LQ6X3NgM4Ow"
   },
   "source": [
    "# 基础 RNN：单步反向传播\n",
    "由于我们使用 PyTorch 实现了 `rnn_step_forward`，因此**不需要**再手动实现 `rnn_step_backward`。我们可以通过数值梯度检查器来验证 PyTorch 自动求导（autograd）的反向传播是否正确。\n",
    "\n",
    "不过，如果你有兴趣，可以尝试自己实现 `rnn_step_backward`。但这并不是本作业的要求。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LbQvmewZM4Ow"
   },
   "outputs": [],
   "source": [
    "from cs231n.rnn_layers_pytorch import rnn_step_forward  # 从对应模块导入RNN单步前向传播函数\n",
    "\n",
    "# 创建测试输入\n",
    "np.random.seed(231)  # 设置随机种子，保证结果可复现\n",
    "N, D, H = 4, 5, 6  # N：批量大小，D：输入特征维度，H：隐藏层维度\n",
    "x = torch.from_numpy(np.random.randn(N, D))  # 输入数据（随机正态分布）\n",
    "h = torch.from_numpy(np.random.randn(N, H))  # 前一时间步隐藏状态（随机正态分布）\n",
    "Wx = torch.from_numpy(np.random.randn(D, H))  # 输入到隐藏层的权重矩阵（随机正态分布）\n",
    "Wh = torch.from_numpy(np.random.randn(H, H))  # 隐藏层到隐藏层的权重矩阵（随机正态分布）\n",
    "b = torch.from_numpy(np.random.randn(H))  # 偏置项（随机正态分布）\n",
    "\n",
    "# 启用梯度跟踪并执行RNN前向传播\n",
    "for tensor in [x, h, Wx, Wh, b]:\n",
    "  tensor.requires_grad_()  # 为每个张量开启梯度跟踪\n",
    "next_h = rnn_step_forward(x, h, Wx, Wh, b)  # 计算当前时间步的隐藏状态\n",
    "\n",
    "# 模拟随机的上游梯度，并使用PyTorch的自动求导进行反向传播\n",
    "dnext_h = torch.from_numpy(np.random.randn(*next_h.shape))  # 上游梯度（形状与next_h相同）\n",
    "next_h.backward(dnext_h)  # 反向传播，计算梯度\n",
    "\n",
    "# 将梯度收集到单独的numpy数组中\n",
    "dx = x.grad.detach().numpy()  # x的梯度（转为numpy数组）\n",
    "dh = h.grad.detach().numpy()  # h的梯度（转为numpy数组）\n",
    "dWx = Wx.grad.detach().numpy()  # Wx的梯度（转为numpy数组）\n",
    "dWh = Wh.grad.detach().numpy()  # Wh的梯度（转为numpy数组）\n",
    "db = b.grad.detach().numpy()  # b的梯度（转为numpy数组）\n",
    "dnext_h = dnext_h.detach().numpy()  # 上游梯度（转为numpy数组）\n",
    "\n",
    "# 同时将测试输入转换为numpy数组\n",
    "x =  x.detach().numpy()\n",
    "h =  h.detach().numpy()\n",
    "Wx = Wx.detach().numpy()\n",
    "Wh = Wh.detach().numpy()\n",
    "b =  b.detach().numpy()\n",
    "\n",
    "# 包装前向传播函数，使其支持numpy数组的输入和输出\n",
    "# 使用`torch.no_grad()`显式禁用梯度跟踪\n",
    "def rnn_step_forward_numpy(x, h, Wx, Wh, b):\n",
    "  with torch.no_grad():\n",
    "    return rnn_step_forward(\n",
    "        torch.from_numpy(x),\n",
    "        torch.from_numpy(h),\n",
    "        torch.from_numpy(Wx),\n",
    "        torch.from_numpy(Wh),\n",
    "        torch.from_numpy(b),\n",
    "    ).numpy()\n",
    "\n",
    "# 计算数值梯度并进行比较\n",
    "fx = lambda x: rnn_step_forward_numpy(x, h, Wx, Wh, b)  # 以x为变量的函数\n",
    "fh = lambda h: rnn_step_forward_numpy(x, h, Wx, Wh, b)  # 以h为变量的函数\n",
    "fWx = lambda Wx: rnn_step_forward_numpy(x, h, Wx, Wh, b)  # 以Wx为变量的函数\n",
    "fWh = lambda Wh: rnn_step_forward_numpy(x, h, Wx, Wh, b)  # 以Wh为变量的函数\n",
    "fb = lambda b: rnn_step_forward_numpy(x, h, Wx, Wh, b)  # 以b为变量的函数\n",
    "\n",
    "# 计算各参数的数值梯度\n",
    "dx_num = eval_numerical_gradient_array(fx, x, dnext_h)\n",
    "dh_num = eval_numerical_gradient_array(fh, h, dnext_h)\n",
    "dWx_num = eval_numerical_gradient_array(fWx, Wx, dnext_h)\n",
    "dWh_num = eval_numerical_gradient_array(fWh, Wh, dnext_h)\n",
    "db_num = eval_numerical_gradient_array(fb, b, dnext_h)\n",
    "\n",
    "# 你应该会看到误差在1e-9量级或更小\n",
    "print('dx error: ', rel_error(dx_num, dx))  # 打印dx的数值梯度与自动梯度的相对误差\n",
    "print('dh error: ', rel_error(dh_num, dh))  # 打印dh的数值梯度与自动梯度的相对误差\n",
    "print('dWx error: ', rel_error(dWx_num, dWx))  # 打印dWx的数值梯度与自动梯度的相对误差\n",
    "print('dWh error: ', rel_error(dWh_num, dWh))  # 打印dWh的数值梯度与自动梯度的相对误差\n",
    "print('db error: ', rel_error(db_num, db))  # 打印db的数值梯度与自动梯度的相对误差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XcjaPfgEM4Ox"
   },
   "source": [
    "# 基础 RNN：完整前向传播\n",
    "既然你已经实现了基础 RNN 单个时间步的前向传播，接下来你将使用它来实现一个能够处理整个数据序列的 RNN。\n",
    "\n",
    "在文件 `cs231n/rnn_layers_pytorch.py` 中，实现函数 `rnn_forward`。该函数应使用你上面定义的 `rnn_step_forward` 函数来实现。完成后，运行下面的代码检查你的实现。你应该会看到误差在 `e-7` 量级或更小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VpZiQIWfM4Ox"
   },
   "outputs": [],
   "source": [
    "from cs231n.rnn_layers_pytorch import rnn_forward  # 从对应模块导入RNN完整前向传播函数\n",
    "\n",
    "# 定义参数：N（批量大小）、T（时间步数）、D（输入特征维度）、H（隐藏层维度）\n",
    "N, T, D, H = 2, 3, 4, 5\n",
    "\n",
    "# 创建输入数据x（形状为N×T×D），从-0.1到0.3均匀生成N*T*D个值\n",
    "x = torch.from_numpy(np.linspace(-0.1, 0.3, num=N*T*D).reshape(N, T, D))\n",
    "# 创建初始隐藏状态h0（形状为N×H），从-0.3到0.1均匀生成N*H个值\n",
    "h0 = torch.from_numpy(np.linspace(-0.3, 0.1, num=N*H).reshape(N, H))\n",
    "# 创建输入到隐藏层的权重矩阵Wx（形状为D×H），从-0.2到0.4均匀生成D*H个值\n",
    "Wx = torch.from_numpy(np.linspace(-0.2, 0.4, num=D*H).reshape(D, H))\n",
    "# 创建隐藏层到隐藏层的权重矩阵Wh（形状为H×H），从-0.4到0.1均匀生成H*H个值\n",
    "Wh = torch.from_numpy(np.linspace(-0.4, 0.1, num=H*H).reshape(H, H))\n",
    "# 创建偏置项b（长度为H），从-0.7到0.1均匀生成H个值\n",
    "b = torch.from_numpy(np.linspace(-0.7, 0.1, num=H))\n",
    "\n",
    "# 执行RNN完整前向传播，获取所有时间步的隐藏状态，转换为numpy数组\n",
    "h = rnn_forward(x, h0, Wx, Wh, b).numpy()\n",
    "# 预期的输出结果（用于验证实现正确性）\n",
    "expected_h = np.asarray([\n",
    "  [\n",
    "    [-0.42070749, -0.27279261, -0.11074945,  0.05740409,  0.22236251],\n",
    "    [-0.39525808, -0.22554661, -0.0409454,   0.14649412,  0.32397316],\n",
    "    [-0.42305111, -0.24223728, -0.04287027,  0.15997045,  0.35014525],\n",
    "  ],\n",
    "  [\n",
    "    [-0.55857474, -0.39065825, -0.19198182,  0.02378408,  0.23735671],\n",
    "    [-0.27150199, -0.07088804,  0.13562939,  0.33099728,  0.50158768],\n",
    "    [-0.51014825, -0.30524429, -0.06755202,  0.17806392,  0.40333043]]])\n",
    "\n",
    "# 计算并打印h与预期结果的相对误差\n",
    "print('h error: ', rel_error(expected_h, h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xfz241ZSM4Ox"
   },
   "source": [
    "# 基础 RNN：反向传播\n",
    "和之前一样，我们可以使用数值梯度检查器来验证 PyTorch 自动求导的反向传播是否正确。如果你愿意，也可以尝试自己实现 `rnn_step_backward`。但这并不是本作业的要求。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ISoLifg1M4Ox"
   },
   "outputs": [],
   "source": [
    "from cs231n.rnn_layers_pytorch import rnn_forward  # 从对应模块导入RNN完整前向传播函数\n",
    "\n",
    "# 创建测试输入\n",
    "np.random.seed(231)  # 设置随机种子，保证结果可复现\n",
    "# N：批量大小，D：输入特征维度，T：时间步数，H：隐藏层维度\n",
    "N, D, T, H = 2, 3, 10, 5\n",
    "x = torch.from_numpy(np.random.randn(N, T, D))  # 输入数据（随机正态分布，形状为N×T×D）\n",
    "h0 = torch.from_numpy(np.random.randn(N, H))  # 初始隐藏状态（随机正态分布，形状为N×H）\n",
    "Wx = torch.from_numpy(np.random.randn(D, H))  # 输入到隐藏层的权重矩阵（随机正态分布，形状为D×H）\n",
    "Wh = torch.from_numpy(np.random.randn(H, H))  # 隐藏层到隐藏层的权重矩阵（随机正态分布，形状为H×H）\n",
    "b = torch.from_numpy(np.random.randn(H))  # 偏置项（随机正态分布，长度为H）\n",
    "\n",
    "# 启用梯度跟踪并执行前向传播\n",
    "for tensor in [x, h0, Wx, Wh, b]:\n",
    "  tensor.requires_grad_()  # 为每个张量开启梯度跟踪\n",
    "h = rnn_forward(x, h0, Wx, Wh, b)  # 计算所有时间步的隐藏状态\n",
    "\n",
    "# 模拟随机的上游梯度，并使用PyTorch的自动求导进行反向传播\n",
    "dh = torch.from_numpy(np.random.randn(*h.shape))  # 上游梯度（形状与h相同）\n",
    "h.backward(dh)  # 反向传播，计算梯度\n",
    "\n",
    "# 将梯度收集到单独的numpy数组中\n",
    "dx = x.grad.detach().numpy()  # x的梯度（转为numpy数组）\n",
    "dh0 = h0.grad.detach().numpy()  # h0的梯度（转为numpy数组）\n",
    "dWx = Wx.grad.detach().numpy()  # Wx的梯度（转为numpy数组）\n",
    "dWh = Wh.grad.detach().numpy()  # Wh的梯度（转为numpy数组）\n",
    "db = b.grad.detach().numpy()  # b的梯度（转为numpy数组）\n",
    "dh = dh.detach().numpy()  # 上游梯度（转为numpy数组）\n",
    "\n",
    "# 同时将测试输入转换为numpy数组\n",
    "x = x.detach().numpy()\n",
    "h0 = h0.detach().numpy()\n",
    "Wx = Wx.detach().numpy()\n",
    "Wh = Wh.detach().numpy()\n",
    "b = b.detach().numpy()\n",
    "\n",
    "# 包装前向传播函数，使其支持numpy数组的输入和输出\n",
    "# 使用`torch.no_grad()`显式禁用梯度跟踪\n",
    "def rnn_forward_numpy(x, h0, Wx, Wh, b):\n",
    "  with torch.no_grad():\n",
    "    return rnn_forward(\n",
    "        torch.from_numpy(x),\n",
    "        torch.from_numpy(h0),\n",
    "        torch.from_numpy(Wx),\n",
    "        torch.from_numpy(Wh),\n",
    "        torch.from_numpy(b),\n",
    "    ).numpy()\n",
    "\n",
    "# 定义以不同参数为变量的函数，用于数值梯度计算\n",
    "fx = lambda x: rnn_forward_numpy(x, h0, Wx, Wh, b)  # 以x为变量的函数\n",
    "fh0 = lambda h0: rnn_forward_numpy(x, h0, Wx, Wh, b)  # 以h0为变量的函数\n",
    "fWx = lambda Wx: rnn_forward_numpy(x, h0, Wx, Wh, b)  # 以Wx为变量的函数\n",
    "fWh = lambda Wh: rnn_forward_numpy(x, h0, Wx, Wh, b)  # 以Wh为变量的函数\n",
    "fb = lambda b: rnn_forward_numpy(x, h0, Wx, Wh, b)  # 以b为变量的函数\n",
    "\n",
    "# 计算各参数的数值梯度\n",
    "dx_num = eval_numerical_gradient_array(fx, x, dh)\n",
    "dh0_num = eval_numerical_gradient_array(fh0, h0, dh)\n",
    "dWx_num = eval_numerical_gradient_array(fWx, Wx, dh)\n",
    "dWh_num = eval_numerical_gradient_array(fWh, Wh, dh)\n",
    "db_num = eval_numerical_gradient_array(fb, b, dh)\n",
    "\n",
    "# 你应该会看到误差在1e-6量级或更小\n",
    "print('dx error: ', rel_error(dx_num, dx))  # 打印dx的数值梯度与自动梯度的相对误差\n",
    "print('dh0 error: ', rel_error(dh0_num, dh0))  # 打印dh0的数值梯度与自动梯度的相对误差\n",
    "print('dWx error: ', rel_error(dWx_num, dWx))  # 打印dWx的数值梯度与自动梯度的相对误差\n",
    "print('dWh error: ', rel_error(dWh_num, dWh))  # 打印dWh的数值梯度与自动梯度的相对误差\n",
    "print('db error: ', rel_error(db_num, db))  # 打印db的数值梯度与自动梯度的相对误差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oVTPWFTlM4Ox"
   },
   "source": [
    "# 词嵌入：前向传播\n",
    "在深度学习系统中，我们通常使用向量来表示单词。词汇表中的每个单词都会与一个向量相关联，这些向量会与系统的其他部分一起被联合学习。\n",
    "\n",
    "在文件 `cs231n/rnn_layers_pytorch.py` 中，实现函数 `word_embedding_forward`，将单词（以整数表示）转换为向量。运行下面的代码检查你的实现。你应该会看到误差在 `e-8` 量级或更小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3aNvH9o6M4Ox"
   },
   "outputs": [],
   "source": [
    "# 定义参数：N（批量大小）、T（时间步数/序列长度）、V（词汇表大小）、D（词向量维度）\n",
    "N, T, V, D = 2, 4, 5, 3\n",
    "\n",
    "# 创建输入x（形状为N×T），每个元素是词汇表中的整数索引\n",
    "x = torch.from_numpy(np.asarray([[0, 3, 1, 2], [2, 1, 0, 3]]))\n",
    "# 创建词嵌入矩阵W（形状为V×D），从0到1均匀生成V*D个值\n",
    "W = torch.from_numpy(np.linspace(0, 1, num=V*D).reshape(V, D))\n",
    "\n",
    "# 执行词嵌入前向传播，将整数索引转换为词向量，结果转为numpy数组\n",
    "out = word_embedding_forward(x, W).numpy()\n",
    "# 预期的输出结果（用于验证实现正确性）\n",
    "expected_out = np.asarray([\n",
    " [[ 0.,          0.07142857,  0.14285714],\n",
    "  [ 0.64285714,  0.71428571,  0.78571429],\n",
    "  [ 0.21428571,  0.28571429,  0.35714286],\n",
    "  [ 0.42857143,  0.5,         0.57142857]],\n",
    " [[ 0.42857143,  0.5,         0.57142857],\n",
    "  [ 0.21428571,  0.28571429,  0.35714286],\n",
    "  [ 0.,          0.07142857,  0.14285714],\n",
    "  [ 0.64285714,  0.71428571,  0.78571429]]])\n",
    "\n",
    "# 计算并打印out与预期结果的相对误差\n",
    "print('out error: ', rel_error(expected_out, out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XQoSauo9M4Ox"
   },
   "source": [
    "# 词嵌入：反向传播\n",
    "和之前一样，我们可以使用数值梯度检查器来验证 PyTorch 自动求导的反向传播是否正确。如果你愿意，也可以尝试自己实现 `word_embedding_backward`。但这并不是本作业的要求。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qpu3qVNPM4Oy"
   },
   "outputs": [],
   "source": [
    "np.random.seed(231)  # 设置随机种子，确保结果可复现\n",
    "\n",
    "# 定义参数：N（批量大小）、T（时间步数/序列长度）、V（词汇表大小）、D（词向量维度）\n",
    "N, T, V, D = 50, 3, 5, 6\n",
    "# 生成输入x（形状为N×T），元素为0到V-1之间的随机整数（表示单词索引）\n",
    "x = torch.from_numpy(np.random.randint(V, size=(N, T)))\n",
    "# 生成词嵌入矩阵W（形状为V×D），元素为随机正态分布值\n",
    "W = torch.from_numpy(np.random.randn(V, D))\n",
    "W.requires_grad_()  # 开启W的梯度跟踪\n",
    "\n",
    "# 执行词嵌入前向传播，得到输出out\n",
    "out = word_embedding_forward(x, W)\n",
    "# 生成随机的上游梯度dout（形状与out相同）\n",
    "dout = torch.from_numpy(np.random.randn(*out.shape))\n",
    "out.backward(dout)  # 反向传播，计算梯度\n",
    "\n",
    "# 提取W的梯度并转换为numpy数组\n",
    "dW = W.grad.detach().numpy()\n",
    "# 将输入x、词嵌入矩阵W和上游梯度dout转换为numpy数组\n",
    "x = x.detach().numpy()\n",
    "W = W.detach().numpy()\n",
    "dout = dout.detach().numpy()\n",
    "\n",
    "# 包装词嵌入前向传播函数，使其支持numpy数组输入和输出\n",
    "# 禁用梯度跟踪以提高效率\n",
    "def word_embedding_forward_numpy(x, W):\n",
    "  return word_embedding_forward(\n",
    "      torch.from_numpy(x),\n",
    "      torch.from_numpy(W),\n",
    "  ).numpy()\n",
    "\n",
    "# 定义以W为变量的函数，用于数值梯度计算\n",
    "f = lambda W: word_embedding_forward_numpy(x, W)\n",
    "# 计算W的数值梯度\n",
    "dW_num = eval_numerical_gradient_array(f, W, dout)\n",
    "\n",
    "# 你应该会看到误差在1e-11量级或更小\n",
    "print('dW error: ', rel_error(dW, dW_num))  # 打印dW的自动梯度与数值梯度的相对误差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1P_oO01FM4Oy",
    "tags": []
   },
   "source": [
    "# 时序仿射层\n",
    "在每个时间步，我们使用仿射函数将该时间步的 RNN 隐藏向量转换为词汇表中每个单词的得分。由于这与你在第二次作业中实现的仿射层非常相似，我们已经在 `temporal_affine_forward` 中为你提供了这个函数。运行下面的代码对实现进行数值梯度检查。你应该会看到误差在 `e-9` 量级或更小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5OkSkxTHM4Oy",
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(231)  # 设置随机种子，确保结果可复现\n",
    "\n",
    "# 对时序仿射层进行梯度检查\n",
    "# N：批量大小，T：时间步数，D：输入特征维度，M：输出特征维度（词汇表大小）\n",
    "N, T, D, M = 2, 3, 4, 5\n",
    "# 生成输入x（形状为N×T×D），元素为随机正态分布值\n",
    "x = torch.from_numpy(np.random.randn(N, T, D))\n",
    "# 生成权重矩阵w（形状为D×M），元素为随机正态分布值\n",
    "w = torch.from_numpy(np.random.randn(D, M))\n",
    "# 生成偏置项b（长度为M），元素为随机正态分布值\n",
    "b = torch.from_numpy(np.random.randn(M))\n",
    "\n",
    "# 为输入、权重和偏置开启梯度跟踪\n",
    "for tensor in [x, w, b]:\n",
    "  tensor.requires_grad_()\n",
    "# 执行时序仿射层前向传播\n",
    "out = temporal_affine_forward(x, w, b)\n",
    "# 生成随机的上游梯度dout（形状与out相同）\n",
    "dout = torch.from_numpy(np.random.randn(*out.shape))\n",
    "# 反向传播，计算梯度\n",
    "out.backward(dout)\n",
    "\n",
    "# 提取各参数的梯度并转换为numpy数组\n",
    "dx = x.grad.detach().numpy()\n",
    "dw = w.grad.detach().numpy()\n",
    "db = b.grad.detach().numpy()\n",
    "\n",
    "# 将输入、权重、偏置和上游梯度转换为numpy数组\n",
    "x = x.detach().numpy()\n",
    "w = w.detach().numpy()\n",
    "b = b.detach().numpy()\n",
    "dout = dout.detach().numpy()\n",
    "\n",
    "# 包装时序仿射层前向传播函数，使其支持numpy数组输入和输出\n",
    "def temporal_affine_forward_numpy(x, w, b):\n",
    "  return temporal_affine_forward(\n",
    "      torch.from_numpy(x),\n",
    "      torch.from_numpy(w),\n",
    "      torch.from_numpy(b),\n",
    "  ).numpy()\n",
    "\n",
    "# 定义以不同参数为变量的函数，用于数值梯度计算\n",
    "fx = lambda x: temporal_affine_forward_numpy(x, w, b)  # 以x为变量的函数\n",
    "fw = lambda w: temporal_affine_forward_numpy(x, w, b)  # 以w为变量的函数\n",
    "fb = lambda b: temporal_affine_forward_numpy(x, w, b)  # 以b为变量的函数\n",
    "\n",
    "# 计算各参数的数值梯度\n",
    "dx_num = eval_numerical_gradient_array(fx, x, dout)\n",
    "dw_num = eval_numerical_gradient_array(fw, w, dout)\n",
    "db_num = eval_numerical_gradient_array(fb, b, dout)\n",
    "\n",
    "# 打印各参数的自动梯度与数值梯度的相对误差\n",
    "print('dx error: ', rel_error(dx_num, dx))\n",
    "print('dw error: ', rel_error(dw_num, dw))\n",
    "print('db error: ', rel_error(db_num, db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ju-dTh4mM4Oy",
    "tags": []
   },
   "source": [
    "# 时序softmax损失\n",
    "在RNN语言模型中，每个时间步我们都会为词汇表中的每个单词生成一个得分。我们知道每个时间步的真实单词，因此我们使用softmax损失函数来计算每个时间步的损失和梯度。我们对所有时间步的损失求和，然后在小批量数据上取平均值。\n",
    "\n",
    "但这里有一个需要注意的地方：由于我们处理的是小批量数据，且不同的描述可能有不同的长度，因此我们会在每个描述的末尾添加`<NULL>`标记，使它们具有相同的长度。我们不希望这些`<NULL>`标记对损失或梯度产生影响，因此除了得分和真实标签外，我们的损失函数还接受一个`mask`数组，用于指示哪些得分元素需要计入损失。\n",
    "\n",
    "由于这与你在第一次作业中实现的softmax损失函数非常相似，我们已经为你实现了这个损失函数；你可以查看`cs231n/rnn_layers_pytorch.py`文件中的`temporal_softmax_loss`函数。\n",
    "\n",
    "运行下面的单元格，对损失进行合理性检查，并对该函数进行数值梯度检查。你应该会看到dx的误差在`e-7`量级或更小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CGXy6nvZM4Oy",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 对时序softmax损失进行合理性检查\n",
    "from cs231n.rnn_layers_pytorch import temporal_softmax_loss  # 从对应模块导入时序softmax损失函数\n",
    "\n",
    "N, T, V = 100, 1, 10  # N：批量大小，T：时间步数，V：词汇表大小\n",
    "\n",
    "def check_loss(N, T, V, p):\n",
    "    # 生成输入x（形状为N×T×V），值很小（接近0），减少数值误差影响\n",
    "    x = 0.001 * torch.from_numpy(np.random.randn(N, T, V))\n",
    "    # 生成真实标签y（形状为N×T），元素为0到V-1之间的随机整数\n",
    "    y = torch.from_numpy(np.random.randint(V, size=(N, T)))\n",
    "    # 生成mask数组（形状为N×T），元素为布尔值，True的概率为p（表示该位置计入损失）\n",
    "    mask = torch.from_numpy(np.random.rand(N, T)) <= p\n",
    "    # 计算并打印时序softmax损失值\n",
    "    print(temporal_softmax_loss(x, y, mask).item())\n",
    "\n",
    "# 测试不同参数下的损失值（用于合理性检查）\n",
    "check_loss(100, 1, 10, 1.0)   # 应约为2.3（ln(10)≈2.3）\n",
    "check_loss(100, 10, 10, 1.0)  # 应约为23（10个时间步，损失累加）\n",
    "check_loss(5000, 10, 10, 0.1) # 应在2.2-2.4之间（mask筛选后约10%的元素有效）\n",
    "\n",
    "# 对时序softmax损失进行梯度检查\n",
    "np.random.seed(231231)  # 设置随机种子，确保结果可复现\n",
    "N, T, V = 7, 8, 9  # 重新定义参数\n",
    "\n",
    "# 生成输入x（形状为N×T×V），元素为随机正态分布值\n",
    "x = torch.from_numpy(np.random.randn(N, T, V))\n",
    "# 生成真实标签y（形状为N×T）\n",
    "y = torch.from_numpy(np.random.randint(V, size=(N, T)))\n",
    "# 生成mask数组（形状为N×T），元素为布尔值（随机筛选约50%的元素有效）\n",
    "mask = torch.from_numpy(np.random.rand(N, T) > 0.5)\n",
    "\n",
    "x.requires_grad_()  # 开启x的梯度跟踪\n",
    "# 计算时序softmax损失（关闭详细输出）\n",
    "loss = temporal_softmax_loss(x, y, mask, verbose=False)\n",
    "loss.backward()  # 反向传播，计算梯度\n",
    "dx = x.grad.detach().numpy()  # 提取x的梯度并转换为numpy数组\n",
    "x = x.detach().numpy()  # 将x转换为numpy数组\n",
    "\n",
    "# 计算x的数值梯度\n",
    "dx_num = eval_numerical_gradient(\n",
    "    lambda x: temporal_softmax_loss(torch.from_numpy(x), y, mask), x, verbose=False)\n",
    "\n",
    "# 打印x的自动梯度与数值梯度的相对误差\n",
    "print('dx error: ', rel_error(dx, dx_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ekrVJdaVM4Oy"
   },
   "source": [
    "# 用于图像描述生成的RNN\n",
    "既然你已经实现了所需的各个层，现在可以将它们组合起来构建一个图像描述生成模型。打开文件 `cs231n/classifiers/rnn_pytorch.py` 并查看 `CaptioningRNN` 类。\n",
    "\n",
    "在 `loss` 函数中实现模型的前向传播。目前你只需要实现 `cell_type='rnn'`（基础RNN）的情况；稍后你将实现LSTM的情况。完成后，运行下面的代码，使用一个小的测试用例检查你的前向传播；你应该会看到误差在 `e-10` 量级或更小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KUR0MJKxM4Oy",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 定义参数：N（批量大小）、D（图像特征维度）、W（词向量维度）、H（隐藏层维度）\n",
    "N, D, W, H = 10, 20, 30, 40\n",
    "# 单词到索引的映射字典（<NULL>为填充标记，cat和dog为示例单词）\n",
    "word_to_idx = {'<NULL>': 0, 'cat': 2, 'dog': 3}\n",
    "V = len(word_to_idx)  # 词汇表大小（等于映射字典的长度）\n",
    "T = 13  # 每个描述的时间步数（序列长度）\n",
    "\n",
    "# 创建图像描述生成模型（RNN）\n",
    "model = CaptioningRNN(\n",
    "    word_to_idx,       # 单词到索引的映射\n",
    "    input_dim=D,       # 输入图像特征的维度\n",
    "    wordvec_dim=W,     # 词向量的维度\n",
    "    hidden_dim=H,      # 隐藏层的维度\n",
    "    cell_type='rnn',   # 使用基础RNN单元\n",
    "    dtype=torch.float64  # 数据类型（双精度浮点数，减少数值误差）\n",
    ")\n",
    "\n",
    "# 将模型的所有参数设置为固定值（用于测试一致性）\n",
    "for k, v in model.params.items():\n",
    "    # 生成从-1.4到1.3均匀分布的数值，形状与参数v一致\n",
    "    model.params[k] = torch.from_numpy(\n",
    "        np.linspace(-1.4, 1.3, num=v.numel()).reshape(*v.shape))\n",
    "\n",
    "# 生成输入图像特征（形状为N×D），值从-1.5到0.3均匀分布\n",
    "features = torch.from_numpy(np.linspace(-1.5, 0.3, num=(N * D)).reshape(N, D))\n",
    "# 生成描述序列（形状为N×T），元素为0到V-1的循环整数（模拟单词索引）\n",
    "captions = torch.from_numpy((np.arange(N * T) % V).reshape(N, T))\n",
    "\n",
    "# 计算模型的损失值（标量）\n",
    "loss = model.loss(features, captions).item()\n",
    "# 预期的损失值（用于验证实现正确性）\n",
    "expected_loss = 9.83235591003\n",
    "\n",
    "# 打印计算得到的损失、预期损失以及两者的差值\n",
    "print('loss: ', loss)\n",
    "print('expected loss: ', expected_loss)\n",
    "print('difference: ', abs(loss - expected_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yYnT5Wv6M4Oy"
   },
   "source": [
    "运行下面的单元格，对 `CaptioningRNN` 类进行数值梯度检查；你应该会看到误差在 `e-6` 量级左右或更小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kpJoG9KyM4Oy"
   },
   "outputs": [],
   "source": [
    "np.random.seed(231)  # 设置numpy随机种子，确保结果可复现\n",
    "torch.manual_seed(231)  # 设置PyTorch随机种子，确保结果可复现\n",
    "\n",
    "# 定义参数：批量大小、时间步数、输入维度、词向量维度、隐藏层维度\n",
    "batch_size = 2\n",
    "timesteps = 3\n",
    "input_dim = 4\n",
    "wordvec_dim = 5\n",
    "hidden_dim = 6\n",
    "# 单词到索引的映射字典\n",
    "word_to_idx = {'<NULL>': 0, 'cat': 2, 'dog': 3}\n",
    "vocab_size = len(word_to_idx)  # 词汇表大小\n",
    "\n",
    "# 生成描述序列（形状为batch_size×timesteps），元素为随机词汇索引\n",
    "captions = torch.from_numpy(np.random.randint(vocab_size, size=(batch_size, timesteps)))\n",
    "# 生成图像特征（形状为batch_size×input_dim），元素为随机正态分布值\n",
    "features = torch.from_numpy(np.random.randn(batch_size, input_dim))\n",
    "\n",
    "# 创建图像描述生成模型（RNN）\n",
    "model = CaptioningRNN(\n",
    "    word_to_idx,       # 单词到索引的映射\n",
    "    input_dim=input_dim,  # 输入图像特征的维度\n",
    "    wordvec_dim=wordvec_dim,  # 词向量的维度\n",
    "    hidden_dim=hidden_dim,    # 隐藏层的维度\n",
    "    cell_type='rnn',   # 使用基础RNN单元\n",
    "    dtype=torch.float64,  # 数据类型（双精度浮点数）\n",
    ")\n",
    "\n",
    "# 为模型所有参数开启梯度跟踪\n",
    "for k, v in model.params.items():\n",
    "  v.requires_grad_()\n",
    "# 计算损失\n",
    "loss = model.loss(features, captions)\n",
    "# 反向传播计算梯度\n",
    "loss.backward()\n",
    "# 收集各参数的梯度并转换为numpy数组\n",
    "grads = {k: v.grad.detach().numpy() for k, v in model.params.items()}\n",
    "# 关闭所有参数的梯度跟踪\n",
    "for k, v in model.params.items():\n",
    "  v.requires_grad_(False)\n",
    "\n",
    "# 对每个参数进行数值梯度检查\n",
    "for param_name in sorted(grads.keys()):\n",
    "    # 定义一个函数，用于计算当参数为val时的损失\n",
    "    def fn(val):\n",
    "      model.params[param_name] = torch.from_numpy(val)  # 将val设置为当前参数值\n",
    "      ret = model.loss(features, captions).numpy()  # 计算损失并转为numpy数组\n",
    "      return ret\n",
    "\n",
    "    # 计算该参数的数值梯度\n",
    "    param_grad_num = eval_numerical_gradient(\n",
    "        fn, model.params[param_name].numpy(), verbose=False, h=1e-6)\n",
    "\n",
    "    # 计算数值梯度与自动梯度的相对误差\n",
    "    e = rel_error(param_grad_num, grads[param_name])\n",
    "    # 打印参数名及其相对误差\n",
    "    print('%s relative error: %e' % (param_name, e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SuWAK9M5M4Oy"
   },
   "source": [
    "# 在小数据集上过度拟合RNN图像描述模型\n",
    "与我们在之前作业中用于训练图像分类模型的`Solver`类类似，在本作业中，我们使用`CaptioningSolverPytorch`类来训练图像描述模型。打开文件`cs231n/captioning_solver_pytorch.py`，阅读`CaptioningSolverPytorch`类的代码；它看起来会非常熟悉。\n",
    "\n",
    "在熟悉了这个API之后，运行下面的代码，确保你的模型能够在包含100个训练样本的小数据集上过度拟合。你应该会看到最终损失小于0.1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6_VTRf13M4Oy"
   },
   "outputs": [],
   "source": [
    "np.random.seed(231)  # 设置numpy随机种子，保证结果可复现\n",
    "torch.manual_seed(231)  # 设置PyTorch随机种子，保证结果可复现\n",
    "\n",
    "# 加载COCO数据集的小样本（最多50个训练样本）\n",
    "small_data = load_coco_data(max_train=50)\n",
    "\n",
    "# 创建一个基于RNN的图像描述模型\n",
    "small_rnn_model = CaptioningRNN(\n",
    "    cell_type='rnn',  # 使用基础RNN单元\n",
    "    word_to_idx=data['word_to_idx'],  # 单词到索引的映射字典\n",
    "    input_dim=data['train_features'].shape[1],  # 输入图像特征的维度\n",
    "    hidden_dim=512,  # 隐藏层维度\n",
    "    wordvec_dim=256,  # 词向量维度\n",
    ")\n",
    "\n",
    "# 创建图像描述模型的求解器（用于训练）\n",
    "small_rnn_solver = CaptioningSolverPytorch(\n",
    "    small_rnn_model, small_data,  # 模型和数据集\n",
    "    num_epochs=50,  # 训练的轮数\n",
    "    batch_size=25,  # 批量大小\n",
    "    learning_rate=5e-3,  # 学习率\n",
    "    verbose=True,  # 训练过程中打印详细信息\n",
    "    print_every=10,  # 每10次迭代打印一次信息\n",
    ")\n",
    "\n",
    "# 开始训练模型\n",
    "small_rnn_solver.train()\n",
    "\n",
    "# 绘制训练损失曲线\n",
    "plt.plot(small_rnn_solver.loss_history)\n",
    "plt.xlabel('Iteration')  # x轴标签：迭代次数\n",
    "plt.ylabel('Loss')  # y轴标签：损失值\n",
    "plt.title('Training loss history')  # 图表标题：训练损失历史\n",
    "plt.show()  # 显示图表"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ExNiqxH8M4Oz"
   },
   "source": [
    "打印最终的训练损失。你应该会看到最终损失小于0.1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CK3iTyxzM4Oz",
    "test": "rnn_final_training_loss"
   },
   "outputs": [],
   "source": [
    "# 打印训练过程中的最终损失值\n",
    "# loss_history存储了训练过程中每一步的损失，[-1]表示取最后一个元素（即最终损失）\n",
    "print('Final loss: ', small_rnn_solver.loss_history[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I_cv_5ppM4Oz"
   },
   "source": [
    "# RNN在测试时的采样\n",
    "与分类模型不同，图像描述模型在训练时和测试时的行为有很大差异。在训练时，我们可以获取真实的描述文本，因此在每个时间步，我们将真实单词作为输入馈送到RNN中。而在测试时，我们在每个时间步从词汇表的概率分布中进行采样，并将该采样结果作为下一个时间步的输入馈送到RNN中。\n",
    "\n",
    "在文件`cs231n/classifiers/rnn_pytorch.py`中，实现用于测试时采样的`sample`方法。完成后，运行下面的代码，从你的过拟合模型中对训练数据和验证数据进行采样。训练数据上的采样结果应该会很好。不过，验证数据上的采样结果可能没什么意义。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "19-MgyZUM4Oz",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 如果你遇到错误，可能是URL已失效，不用担心！\n",
    "# 你可以根据需要多次重新采样\n",
    "\n",
    "# 分别对训练集和验证集进行采样测试\n",
    "for split in ['train', 'val']:\n",
    "    # 从数据集中抽取一个小批量样本（包含真实描述、图像特征和图像URL）\n",
    "    minibatch = sample_coco_minibatch(small_data, split=split, batch_size=2)\n",
    "    gt_captions, features, urls = minibatch\n",
    "    # 将真实描述的索引转换为文字（解码）\n",
    "    gt_captions = decode_captions(gt_captions, data['idx_to_word'])\n",
    "\n",
    "    # 使用训练好的模型对图像特征进行采样，生成描述（索引形式），再转换为numpy数组\n",
    "    sample_captions = small_rnn_model.sample(torch.from_numpy(features)).numpy()\n",
    "    # 将生成的描述索引转换为文字（解码）\n",
    "    sample_captions = decode_captions(sample_captions, data['idx_to_word'])\n",
    "\n",
    "    # 遍历每个样本，显示图像及对应的真实描述和生成描述\n",
    "    for gt_caption, sample_caption, url in zip(gt_captions, sample_captions, urls):\n",
    "        # 从URL加载图像\n",
    "        img = image_from_url(url)\n",
    "        # 跳过无效的URL（图像无法加载的情况）\n",
    "        if img is None: continue\n",
    "        # 显示图像\n",
    "        plt.imshow(img)\n",
    "        # 设置图像标题，包含数据集划分（训练/验证）、生成的描述和真实描述\n",
    "        plt.title('%s\\n%s\\nGT:%s' % (split, sample_caption, gt_caption))\n",
    "        # 关闭坐标轴显示\n",
    "        plt.axis('off')\n",
    "        # 显示图像\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x9gU1OwkM4Oz",
    "tags": [
     "pdf-inline"
    ]
   },
   "source": [
    "# 内联问题1\n",
    "\n",
    "在我们当前的图像描述设置中，我们的RNN语言模型在每个时间步都会输出一个单词作为其结果。然而，另一种解决该问题的方式是训练网络以**字符**（例如'a'、'b'等）为操作单位，而不是单词，这样在每个时间步，网络会接收前一个字符作为输入，并尝试预测序列中的下一个字符。例如，网络可能会生成这样的描述：\n",
    "\n",
    "'A'、' '、'c'、'a'、't'、' '、'o'、'n'、' '、'a'、' '、'b'、'e'、'd'\n",
    "\n",
    "你能描述使用字符级RNN的图像描述模型的一个优点吗？你还能描述一个缺点吗？提示：有几个合理的答案，但比较单词级模型和字符级模型的参数空间可能会有所帮助。\n",
    "\n",
    "**你的答案：**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pdHe3qPI2dFl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
